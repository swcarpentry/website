---
layout: page
date: 2009-05-11
time: "09:00:00"
authors: ["Greg Wilson"]
title: Links for Summer Interns
tags: ["Content", "Software Carpentry"]
---

<p><b>This post originally appeared on the <a href="https://software-carpentry.org/">Software Carpentry website.</a></b></p>
<p>Our summer interns started today; our first job is to define exactly what they'll be working on this summer, so it seems like a good time to round up a few links on interesting topics. My apologies for those hidden behind paywalls...</p>
<p><strong>Steve's Project Ideas</strong></p>
<ol>
<li><a href="http://www.easterbrook.ca/steve/?p=430">Social network analysis for scientists</a></li>
<li>Electronic lab notebooks</li>
</ol>
<p><strong>Reproducible Research</strong></p>
<p>If I said, "I just got a really interesting result in the lab, but I didn't record the steps I took or the settings on the machine," no reputable journal would publish my paper.  If I said, "I just got a really interesting <em>computational</em> result," most reviewers and editors wouldn't even ask if I'd archived my code and the parameters I used, or whether that code would run on someone else's machine.  Reproducible research (RR) is the idea of making computational science as trustworthy as experimental science by creating tools and working practices that will allow scientists to re-create past results.</p>
<ol>
<li><a href="http://www-stat.stanford.edu/~donoho/Reports/1995/wavelab.pdf">WaveLab and Reproducible Research</a></li>
<li>The <a href="http://www.beg.utexas.edu/mainweb/services/madagascar.htm">Madagascar</a> project</li>
<li>The <a href="http://www.stat.uni-muenchen.de/~leisch/Sweave/">Sweave</a> project</li>
<li><a href="http://cise.aip.org/dbt/dbt.jsp?KEY=CSENFA&amp;Volume=11&amp;Issue=1">Special issue</a> of <em>Computing in Science &amp; Engineering</em> on reproducibility</li>
</ol>
<p><strong>Data Provenance</strong></p>
<p>The "provenance" of an object is the history of where it came from, and how it got here.  The provenance of a piece of data is similar: what raw values is it derived from, and what processing was done to create it?  Ideally, every piece of scientific software should track this automatically; in practice, very few do, and most scientists don't take advantage of the capability when it's there.  That's changing, though, particularly as emphasis on reproducibility grows.</p>
<ol>
<li>The <a href="http://openprovenance.org/">Provenance Challenge</a>: a series of competitions to benchmark provenance tools against one another.</li>
<li><a href="http://portal.acm.org/citation.cfm?id=1350745.1350753">Special issue</a> of <em>Concurrency and Computation: Practice &amp; Experience</em> reporting the results of the first challenge</li>
</ol>
<p><strong>Science 2.0</strong></p>
<p>Also called "computer-supported collaborative science", this is the idea of leveraging modern web-based collaboration tools to better connect scientists, their experiments, and their results.  It encompasses a broad range of ideas, but "social networking for scientists" based on their interests is near the core, as is "open science" (the idea of making scientific results public in the same way as <a href="http://opensource.org">open source software</a> or <a href="http://creativecommons.org/">Creative Commons</a> publications).</p>
<ol>
<li><a href="http://www.scientificamerican.com/article.cfm?id=science-2-point-0-great-new-tool-or-great-risk">Overview article</a> in <em>Scientific American</em></li>
<li>Jon Udell's <em><a href="http://jonudell.net/GroupwareReport.html">Internet Groupware for Scientific Collaboration</a></em> may be several years old, but it's still prescient</li>
<li>Jean Claude Bradley's <a href="http://usefulchem.blogspot.com/">blog</a></li>
<li>Cameron Neylon's <a href="http://blog.openwetware.org/scienceintheopen/">personal blog</a> (see for example his post on "<a href="http://blog.openwetware.org/scienceintheopen/2008/06/12/friendfeed-for-scientists-what-why-and-how/">FriendFeed for Scientists</a>") and <a href="http://biolab.isis.rl.ac.uk/camerons_labblog/">lab blog</a></li>
</ol>
<p><strong>Scientific Programming Environments</strong></p>
<p>Compared to professional software developers, most scientists use fairly primitive programming environments, in part because they've been too busy learning quantum chemistry to learn distributed version control, and in part because software developers seem to go out of their way to make tools hard to set up and learn.  Lots of people have tackled this from a variety of angles.  Unfortunately, a lot of work to date has focused on supercomputing, which is sort of like studying modern medicine by focusing on heart surgeons...</p>
<ol>
<li>Greg Wilson's "<a href="{{site.baseurl}}/files/bib/amsci-swc-2006.pdf">Where's the Real Bottleneck in Scientific Computing?</a>"</li>
<li>Carver, Kendall, Squires, and Post's "<a href="http://portal.acm.org/citation.cfm?id=1248886">Software Development Environments for Scientific and Engineering Software: A Series of Case Studies</a>"</li>
<li>Matthews, Wilson, and Easterbrook's "<a href="http://www2.computer.org/portal/web/csdl/doi/10.1109/MCSE.2008.144">Configuration Management for Large-Scale Scientific Computing at the UK Met Office</a>" is an example of tools done right</li>
</ol>
