---
layout: page
date: 2011-11-29
time: "09:00:00"
authors: ["Greg Wilson"]
title: Three Short Thoughts
tags: ["Opinion", "Software Carpentry"]
---

<p><b>This post originally appeared on the <a href="https://software-carpentry.org/">Software Carpentry website.</a></b></p>
<ol>
<li>A BBC article title "<a href="http://www.bbc.co.uk/news/technology-15916677">Coding &mdash; the New Latin</a>" resonated: Latin was the language of learned discourse in the formative years of modern science, but not something most people spoke day-to-day. I think that's a good model for computing in the sciences; like statistics, it requires familiarity, not expertise.</li>
<li>Jorge Aranda's review of <a href="http://www.neverworkintheory.org/?p=225"><em>Codermetrics</em></a> talks about the limitations to quantification in software engineering. I've <a href="{{site.baseurl}}/blog/2011/11/show-me-the-data.html">said before</a> that we need to measure how much time is lost due to poor computing skills in order to get people to take this kind of training seriously, but I'm very conscious of just how much measurement <em>can't</em> tell us.</li>
<li>Another thought-provoking post by Cameron Neylon asks <a href="http://cameronneylon.net/blog/good-practice-in-research-coding-what-are-the-targets-and-how-do-we-get-there.html">what it's reasonable to expect</a> from scientists, and their software. I'm sure he'd enjoy hearing what you think...</li>
</ol>
